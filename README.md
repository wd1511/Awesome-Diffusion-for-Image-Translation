# Diffusion for Image-to-Image Translation

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/wd1511/Awesome-Diffusion-for-Image-Translation) 

```Latex
**Here is the Paper Name** <br>
*Author 1, ..., Author n.* <br>
**Classification of papers**, Author Affiliation <br>
Conference or Journal Year. [[PDF](link)] [[Project](link)] [[Github](link)] [[Data](link)] <br>
```

Download all PDF files
```
python download.py
```

- [Dataset](#Dataset)
- [2025](#2025)
- [2024](#2024)
- [2023](#2023)
- [2022](#2022)
- [2021](#2021)


## Dataset

### Game Datasets

GTA5 dataset: [[Download](https://download.visinf.tu-darmstadt.de/data/from_games/index.html)] <br>
Viper dataset: [[Download](https://playing-for-benchmarks.org)] <br>

### Real-world Datasets

Cityscapes dataset: [[Download](https://www.cityscapes-dataset.com/downloads/)] <br>
BDD100K dataset: [[Download](https://bdd-data.berkeley.edu)] <br>

### Painter Datasets

Wiki-Art dataset: [[Download1](https://www.kaggle.com/competitions/painter-by-numbers/)] [[Download2](https://huggingface.co/datasets/huggan/wikiart)] <br>

### Common Datasets

ImageNet dataset: [[Download](https://image-net.org/download.php)] <br>
MS-COCO dataset [[Download1](https://cocodataset.org/#download)] [[Download2](https://huggingface.co/datasets/detection-datasets/coco)] <br>
LSUN dataset [[Download1](http://lsun.cs.princeton.edu/2017)] [[Download2](https://hyper.ai/datasets/5675)] [[Download(church)](https://huggingface.co/datasets/tglcourse/lsun_church_train)] [[Download(bedrooms)](https://huggingface.co/datasets/pcuenq/lsun-bedrooms)] <br>
AFHQv2 dataset [[Download1](https://www.dropbox.com/scl/fi/0aha0j1yvhjdnr1r86u0g/?rlkey=ji6v8s9tkma1vg87bwowi9v1e&e=1)] [[Download2](https://huggingface.co/datasets/huggan/AFHQv2)] <br>

### Medical Datasets

Prostate-MRI-US-Biopsy dataset [[Download1](https://www.cancerimagingarchive.net/collection/prostate-mri-us-biopsy/)] [[Download2](https://drive.google.com/file/d/1kF0g8fMR5XPQ2FTbutfTQ-hwG_mTqerx/view)] <br>
LDCT-and-Projection-data  dataset [[Download1](https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=52758026)] [[Download2](https://drive.google.com/file/d/1kF0g8fMR5XPQ2FTbutfTQ-hwG_mTqerx/view)] <br>
BraTS 2018 dataset [[Download1](https://www.med.upenn.edu/sbia/brats2018/)] [[Download2](https://drive.google.com/file/d/1kF0g8fMR5XPQ2FTbutfTQ-hwG_mTqerx/view)] <br>

## 2025

**DyArtbank: Diverse artistic style transfer via pre-trained stable diffusion and dynamic style prompt Artbank** <br>
*Zhanjie Zhang, Quanwei Zhang, Guangyuan Li, Junsheng Luan, Mengyuan Yang, Yun Wang, Lei Zhao.* <br>
**Image Style Transfer**, Zhejiang University & City University of Hong Kong <br>
Knowledge-Based Systems 2025. [[PDF](https://arxiv.org/abs/2503.08392)] 
[[PDF(official)](https://www.sciencedirect.com/science/article/pii/S0950705125000073)] 
[[Github](https://github.com/Jamie-Cheung/DyArtbank)] <br>

**AttenST: A Training-Free Attention-Driven Style Transfer Framework with Pre-Trained Diffusion Models** <br>
*Bo Huang, Wenlun Xu, Qizhuo Han, Haodong Jing, Ying Li.* <br>
**Image Style Transfer**, Northwestern Polytechnical University <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2503.07307)] <br>

**SCSA: A Plug-and-Play Semantic Continuous-Sparse Attention for Arbitrary Semantic Style Transfer** <br>
*Chunnan Shang, Zhizhong Wang, Hongwei Wang, Xiangming Meng.* <br>
**Image Style Transfer**, Zhejiang University <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2503.04119)] <br>

**CAPAST: Content Affinity Preserved Arbitrary Style Transfer** <br>
*Xinyuan Zheng, Xiaojie Li, Canghong Shi, Jia He, Zhan Ao Huang, Xian Zhang.* <br>
**Image Style Transfer**, Chengdu University of Information Technology <br>
ICASSP 2025. [[PDF](https://ieeexplore.ieee.org/abstract/document/10890339)] <br>

**Low-Rank Transformer Adaptation for Arbitrary Style Transfer** <br>
*Wenjie Xu, Meichen Liu, Bihan Wen.* <br>
**Image Style Transfer**, Nanyang Technological University <br>
ICASSP 2025. [[PDF](https://ieeexplore.ieee.org/abstract/document/10887739)] <br>

**Dual-Modality Guided Artistic Style Transfer with Pre-trained Diffusion Models** <br>
*Jiaxiong Liu, Xiaolong Xiong, Jun Zhou.* <br>
**Image Style Transfer**, Southwest University <br>
ICASSP 2025. [[PDF](https://ieeexplore.ieee.org/abstract/document/10888654)] 
[[Github](https://github.com/BBABM/DMG)] <br>

**SSDM: Generated image interaction method based on spatial sparsity for diffusion models** <br>
*Zhuochao Yang, Jingjing Liu, Haozhe Zhu, Jianhua Zhang, Wanquan Liu.* <br>
**Image editing**, Shanghai University & Fudan University <br>
Neurocomputing 2025. [[PDF](https://www.sciencedirect.com/science/article/abs/pii/S0925231225004771)] <br>

**Attention Distillation: A Unified Approach to Visual Characteristics Transfer** <br>
*Yang Zhou, Xu Gao, Zichong Chen, Hui Huang.* <br>
**Image Style Transfer**, Shenzhen University <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2502.20235)]
[[Github](https://github.com/xugao97/AttentionDistillation)] <br>

**PQDAST: Depth-Aware Arbitrary Style Transfer for Games via Perceptual Quality-Guided Distillation** <br>
*Eleftherios Ioannou, Steve Maddock.* <br>
**Image Style Transfer**, The University of Sheffield <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2502.16996)] <br>

**PhotoDoodle: Learning Artistic Image Editing from Few-Shot Pairwise Data** <br>
*Shijie Huang, Yiren Song, Yuxuan Zhang, Hailong Guo, Xueyin Wang, Mike Zheng Shou, Jiaming Liu.* <br>
**Image Editing**, National University of Singapore & Tiamat <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2502.14397v1)] 
[[Github](https://github.com/showlab/PhotoDoodle)] <br>

**SigStyle: Signature Style Transfer via Personalized Text-to-Image Models** <br>
*Ye Wang, Tongyuan Bai, Xuping Xie, Zili Yi, Yilin Wang, Rui Ma.* <br>
**Image Style Transfer**, Jilin University & Nanjing University & Adobe <br>
ICLR 2025. [[PDF](https://arxiv.org/abs/2502.13997)] 
[[Github](https://github.com/linllll/maskst)] <br>

**Image Inversion: A Survey from GANs to Diffusion and Beyond** <br>
*Yinan Chen, Jiangning Zhang, Yali Bi, Xiaobin Hu, Teng Hu, Zhucun Xue, Ran Yi, Yong Liu, Ying Tai.* <br>
**Else Papers**, Zhejiang University & Tencent <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2502.11974)] 
[[Github](https://github.com/RyanChenYN/ImageInversion)] <br>

**Less is More: Masking Elements in Image Condition Features Avoids Content Leakages in Style Transfer Diffusion Models** <br>
*Lin Zhu, Xinbing Wang, Chenghu Zhou, Qinying Gu, Nanyang Ye.* <br>
**Image Style Transfer**,  Shanghai Jiao Tong University & Chinese Academy of Sciences & Shanghai AI Laboratory <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2502.07466)] <br>

**UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control** <br>
*Kaizhen Zhu, Mokai Pan, Yuexin Ma, Yanwei Fu, Jingyi Yu, Jingya Wang, Ye Shi.* <br>
**Base I2I translation**, ShanghaiTech University & Fudan University <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2502.05749)] 
[[Github](https://github.com/UniDB-SOC/UniDB/)] <br>

**Inverse Bridge Matching Distillation** <br>
**Nikita Gushchin, David Li, Daniil Selikhanovych, Evgeny Burnaev, Dmitry Baranchuk, Alexander Korotin.* <br>
**Base I2I translation**, Skolkovo Institute of Science and Technology & Yandex Research & HSE University & Artificial Intelligence Research Institute <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2502.01362)] <br>

**A Diffusion Model Translator for Efficient Image-to-Image Translation** <br>
*Mengfei Xia, Yu Zhou, Ran Yi, Yong-Jin Liu, Wenping Wang.* <br>
**Base I2I translation**, Shanghai Jiao Tong University & Texas A&M University <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2502.00307)] <br>

**Style transfer as data augmentation: evaluating unpaired image-to-image translation models in mammography** <br>
*Emir Ahmed, Spencer A. Thomas, Ciaran Bench.* <br>
**Medical Image Translation**, National Physical Laboratory <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2502.02475)] 
[[PDF(old)](https://arxiv.org/abs/2501.17570)] <br>

**Training-Free Style and Content Transfer by Leveraging U-Net Skip Connections in Stable Diffusion 2** <br>
*Ludovica Schaerf, Andrea Alfarano, Fabrizio Silvestri, Leonardo Impett.* <br>
**Style Transfer**, Max Planck Society University of Zurich Zurich <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2501.14524)] <br>

**Generating Realistic Forehead-Creases for User Verification via Conditioned Piecewise Polynomial Curves** <br>
*Abhishek Tandon, Geetanjali Sharma, Gaurav Jaswal, Aditya Nigam, Raghavendra Ramachandra.* <br>
**Base I2I translation**, Indian Institute of Technology Mandi <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2501.13889)] <br>

**AMM-Diff: Adaptive Multi-Modality Diffusion Network for Missing Modality Imputation** <br>
Aghiles Kebaili, Jérôme Lapuyade-Lahorgue, Pierre Vera, Su Ruan.* <br>
**Medical Image Translation**, University of Rouen-Normandy & CLCC Henri Becquerel <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2501.12840)] <br>

**EfficientVITON: An Efficient Virtual Try-On Model using Optimized Diffusion Process** <br>
*Mostafa Atef, Mariam Ayman, Ahmed Rashed, Ashrakat Saeed, Abdelrahman Saeed, Ahmed Fares.* <br>
**virtual try-on**, Egypt-Japan University of Science and Technology <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2501.11776)] <br>

**StyleSSP: Sampling StartPoint Enhancement for Training-free Diffusion-based Method for Style Transfer** <br>
*Ruojun Xu, Weijie Xi, Xiaodi Wang, Yongbo Mao, Zach Cheng.* <br>
**Style Transfer**, Zhejiang University & Dcar <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2501.11319)] <br>

**Generalizable Origin Identification for Text-Guided Image-to-Image Diffusion Models** <br>
*Wenhao Wang, Yifan Sun, Zongxin Yang, Zhentao Tan, Zhengdong Hu, Yi Yang.* <br>
**Base I2I translation**, University of Technology Sydney & Baidu Inc & Zhejiang University <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2501.02376)] <br>

**ArtCrafter: Text-Image Aligning Style Transfer via Embedding Reframing** <br>
*Nisha Huang, Kaer Huang, Yifan Pu, Jiangshan Wang, Jie Guo, Yiqiang Yan, Xiu Li.* <br>
**Image Style Transfer**, Tsinghua University & Peng Cheng Laboratory & Lenovo Research <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2501.02064)] <br>

**Conditional Consistency Guided Image Translation and Enhancement** <br>
*Amil Bhagat, Milind Jain, A. V. Subramanyam.* <br>
**Base I2I translation**, Indraprastha Institute of Information Technology <br>
arXiv 2025. [[PDF](https://arxiv.org/abs/2501.01223)] 
[[Github](https://github.com/amilbhagat/Conditional-Consistency-Models)] <br>

## 2024

**d-Sketch: Improving Visual Fidelity of Sketch-to-Image Translation with Pretrained Latent Diffusion Models without Retraining** <br>
*Prasun Roy, Saumik Bhattacharya, Subhankar Ghosh, Umapada Pal, Michael Blumenstein.* <br>
**Sketch-to-Image translation**, University of Technology Sydney <br>
ICPR 2024. [[PDF](https://arxiv.org/abs/2502.14007)] 
[[Github](https://github.com/prasunroy/dsketch)]<br>

**StyleRWKV: High-Quality and High-Efficiency Style Transfer with RWKV-like Architecture** <br>
*Miaomiao Dai, Qianyu Zhou, Lizhuang Ma.* <br>
**Image Style Transfer**, Shanghai Jiao Tong University <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2412.19535)] <br>

**Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation** <br>
*Nadav Z. Cohen, Oron Nir, Ariel Shamir.* <br>
**Image Style Transfer**, Reichman University & Microsoft Corporation <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2412.19853)] <br>

**Single Trajectory Distillation for Accelerating Image and Video Style Transfer** <br>
*Sijie Xu, Runqi Wang, Wei Zhu, Dejia Song, Nemo Chen, Xu Tang, Yao Hu.* <br>
**Image Style Transfer**, Xiaohongshu & ShanghaiTech University<br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2412.18945)] 
[[Project](https://single-trajectory-distillation.github.io/)] <br>

**Diffusion-Based Conditional Image Editing through Optimized Inference with Guidance** <br>
*Hyunsoo Lee, Minsoo Kang, Bohyung Han.* <br>
**Base I2I translation**, ECE & Seoul National University <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2412.15798)] <br>

**Efficient Fine-Tuning and Concept Suppression for Pruned Diffusion Models** <br>
*Reza Shirkavand, Peiran Yu, Shangqian Gao, Gowthami Somepalli, Tom Goldstein, Heng Huang.* <br>
**Image Style Transfer**, University of Maryland & Florida State University <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2412.15341)] 
[[Github](https://github.com/rezashkv/diffusion_pruning)] <br>

**LineArt: A Knowledge-guided Training-free High-quality Appearance Transfer for Design Drawing with Diffusion Model** <br>
*Xi Wang, Hongzhen Li, Heng Fang, Yichen Peng, Haoran Xie, Xi Yang, Chuntao Li.* <br>
**Image Style Transfer**, KTH Royal Institute of Technology & Tokyo Institute of Technology & Japan Advanced Institute of Science and Technology (JAIST) <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2412.11519)] <br>

**Unpaired Multi-Domain Histopathology Virtual Staining using Dual Path Prompted Inversion** <br>
*Bing Xiong, Yue Peng, RanRan Zhang, Fuqiang Chen, JiaYe He, Wenjian Qin.* <br>
**Virtual Staining**, Shenzhen Institutes of Advanced Technology <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2412.11106v1)]
[[Github](https://github.com/bairdxiong/StainPromptInversion)] <br>

**SHMT: Self-supervised Hierarchical Makeup Transfer via Latent Diffusion Models** <br>
*Zhaoyang Sun, Shengwu Xiong, Yaxiong Chen, Fei Du, Weihua Chen, Fan Wang, Yi Rong.* <br>
**Image Style Transfer**, Wuhan University of Technology & Alibaba & Hupan Laboratory & Shanghai AI Laboratory <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2412.11058)] 
[[Github](https://github.com/Snowfallingplum/SHMT)] <br>

**Learning Artistic Signatures: Symmetry Discovery and Style Transfer** <br>
*Emma Finn, T. Anderson Keller, Emmanouil Theodosis, Demba E. Ba.* <br>
**Image Style Transfer**, Harvard University <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2412.04441)] <br>

**Structure-Aware Stylized Image Synthesis for Robust Medical Image Segmentation** <br>
*Jie Bao, Zhixin Zhou, Wen Jung Li, Rui Luo.* <br>
**Medical Image Translation**, Huaiyin Institute of Technology & Alpha Benito Research & City University of Hong Kong <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2412.04296)] 
[[Github](https://github.com/luo-lorry/Stylized-Medical-Segmentation)] <br>

**Z-STAR+: A Zero-shot Style Transfer Method via Adjusting Style Distribution** <br>
*Yingying Deng, Xiangyu He, Fan Tang, Weiming Dong.* <br>
**Image Style Transfer**, Chinese Academy of Sciences <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2411.19231)] <br>

**Latent Schrodinger Bridge: Prompting Latent Diffusion for Fast Unpaired Image-to-Image Translation** <br>
*Jeongsol Kim, Beomsu Kim, Jong Chul Ye.* <br>
**Base I2I translation**, KAIST <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2411.14863)] <br>

**C-DiffSET: Leveraging Latent Diffusion for SAR-to-EO Image Translation with Confidence-Guided Reliable Object Generation** <br>
*Jeonghyeok Do, Jaehyup Lee, Munchurl Kim.* <br>
**SAR Image Translation**, KAIST & KNU <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2411.10788)] 
[[Project](https://kaist-viclab.github.io/C-DiffSET_site)] 
[[Github](https://github.com/KAIST-VICLab/C-DiffSET)] <br>

**Towards Multi-View Consistent Style Transfer with One-Step Diffusion via Vision Conditioning** <br>
*Yushen Zuo, Jun Xiao, Kin-Chung Chan, Rongkang Dong, Cuixin Yang, Zongqi He, Hao Xie, Kin-Man Lam.* <br>
**Image Style Transfer**, The Hong Kong Polytechnic University <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2411.10130)] <br>

**Diff-TST: Diffusion model for one-shot text-image style transfer** <br>
*Sizhe Pang, Xinyuan Chen, Yangchen Xie, Hongjian Zhan, Bing Yin, Yue Lu.* <br>
**Image Style Transfer**, East China Normal University & Shanghai AI Lab <br>
Expert Systems With Applications. [[PDF](https://www.sciencedirect.com/science/article/pii/S0957417424026149)] <br>

**Multi-layer Feature Fusion based Image Style Transfer with Arbitrary Text Condition** <br>
*Yue Yua, Jingshuo Xing, Nengli Li.* <br>
**Image Style Transfer**, Beijing Institute of Technology <br>
Signal Processing: Image Communication. [[PDF](https://www.sciencedirect.com/science/article/pii/S0923596524001449)] <br>

**DiT4Edit: Diffusion Transformer for Image Editing** <br>
*Kunyu Feng, Yue Ma, Bingyuan Wang, Chenyang Qi, Haozhe Chen, Qifeng Chen, Zeyu Wang.* <br>
**Image Editing**, PKU & HKUST <br>
arXiv 2024. [[PDF](https://arxiv.org/pdf/2411.03286)] 
[[Github](https://github.com/fkyyyy/DiT4Edit)] <br>

**AdvI2I: Adversarial Image Attack on Image-to-Image Diffusion models** <br>
*Yaopei Zeng, Yuanpu Cao, Bochuan Cao, Yurui Chang, Jinghui Chen, Lu Lin.* <br>
**Base I2I translation**, Pennsylvania State University <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2410.21471)] 
[[Github](https://github.com/Spinozaaa/AdvI2I)]<br>

**Beyond Color and Lines: Zero-Shot Style-Specific Image Variations with Coordinated Semantics** <br>
*Jinghao Hu, Yuhe Zhang, GuoHua Geng, Liuyuxin Yang, JiaRui Yan, Jingtao Cheng, YaDong Zhang, Kang Li.* <br>
**Image Style Transfer**, Northwest University <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2410.18537)] <br>

**StyleAdapter: A Unified Stylized Image Generation Model** <br>
*Zhouxia Wang, Xintao Wang, Liangbin Xie, Zhongang Qi, Ying Shan, Wenping Wang, Ping Luo.* <br>
**Image Style transfer**, The University of Hong Kong & Tencent PCG <br>
IJCV 2024. [[PDF1](https://link.springer.com/article/10.1007/s11263-024-02253-x)] 
[[PDF2](https://openreview.net/pdf?id=NaxbdRi8Rv)] <br>

**FashionR2R: Texture-preserving Rendered-to-Real Image Translation with Diffusion Models** <br>
*Rui Hu, Qian He, Gaofeng He, Jiedong Zhuang, Huang Chen, Huafeng Liu, Huamin Wang.* <br>
**Else Papers**, Zhejiang University & Style3D Research <br>
NeurIPS 2024. [[PDF](https://arxiv.org/abs/2410.14429)] 
[[Project](https://rickhh.github.io/FashionR2R/)] 
[[Github](https://github.com/Style3D/FashionR2R)] <br>

**HiCo: Hierarchical Controllable Diffusion Model for Layout-to-image Generation** <br>
*Bo Cheng, Yuhang Ma, Liebucha Wu, Shanyuan Liu, Ao Ma, Xiaoyu Wu, Dawei Leng, Yuhui Yin.* <br>
**Layout2Image**, 360 AI Research <br>
NeurIPS 2024. [[PDF](https://arxiv.org/abs/2410.14324)] <br>

**Harnessing the Latent Diffusion Model for Training-Free Image Style Transfer** <br>
*Kento Masui, Mayu Otani, Masahiro Nomura, Hideki Nakayama.* <br>
**Image Style Transfer**, CyberAgent <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2410.01366)] <br>

**PixelShuffler: A Simple Image Translation Through Pixel Rearrangement** <br>
*Omar Zamzam.* <br>
**Image Style Transfer**, University of Southern California <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2410.03021)] 
[[Github](https://github.com/OmarSZamzam/PixelShuffler)] <br>

**Tuning Timestep-Distilled Diffusion Model Using Pairwise Sample Optimization** <br>
*Zichen Miao, Zhengyuan Yang, Kevin Lin, Ze Wang, Zicheng Liu, Lijuan Wang, Qiang Qiu.* <br>
**Image Style Transfer**, Purdue University & Microsoft & AMD <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2410.03190)] <br>

**EBDM: Exemplar-guided Image Translation with Brownian-bridge Diffusion Models** <br>
*Eungbean Lee, Somi Jeong, Kwanghoon Sohn.* <br>
**Base I2I translation**, Yonsei University & NAVER LABS & KIST <br>
ECCV 2024, [[PDF](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/02096.pdf)] 
[[Github](https://github.com/eungbean/ebdm)] <br>

**A Training-Free Latent Diffusion Style Transfer Method** <br>
*Zhengtao Xiang, Xing Wan, Libo Xu, Xin Yu, Yuhan Mao.* <br>
**Image Style Transfer**, Hubei University of Automotive Technology <br>
Information, [[PDF](https://www.mdpi.com/2078-2489/15/10/588/pdf?version=1727347041)] <br>

**Cross-conditioned Diffusion Model for Medical Image to Image Translation** <br>
*Zhaohu Xing, Sicheng Yang, Sixiang Chen, Tian Ye, Yijun Yang, Jing Qin, Lei Zhu.* <br>
**Medical Image Translation**, HKUST <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2409.08500)] <br>

**MagicStyle: Portrait Stylization Based on Reference Image** <br>
*Zhaoli Deng, Kaibin Zhou, Fanyi Wang, Zhenpeng Mi.* <br>
**Image Style Transfer**, Honor & Tongji University <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2409.08156)] <br>

**Diffusion-Based Image-to-Image Translation by Noise Correction via Prompt Interpolation** <br>
*Junsung Lee, Minsoo Kang, Bohyung Han.* <br>
**Base I2I translation**, ECE & Seoul National University <br>
ECCV 2024, [[PDF](https://arxiv.org/abs/2409.08077)] 
[[Github](https://github.com/jslee525/PIC)] <br>

**TCDiff: Triple Condition Diffusion Model with 3D Constraints for Stylizing Synthetic Faces** <br>
*Bernardo Biesseck, Pedro Vidal, Luiz Coelho, Roger Granada, David Menotti.* <br>
**Face style**, Federal University of Parana <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2409.03600)]
[[Github](https://github.com/BOVIFOCR/tcdiff)] <br>

**StyleTokenizer: Defining Image Style by a Single Instance for Controlling Diffusion Models** <br>
*Wen Li, Muyuan Fang, Cheng Zou, Biao Gong, Ruobing Zheng, Meng Wang, Jingdong Chen, Ming Yang.* <br>
**Image Style Transfer**, Ant Group <br>
ECCV 2024. [[PDF](https://arxiv.org/abs/2409.02543)] 
[[Github](https://github.com/alipay/style-tokenizer)] <br>

**Training-free Color-Style Disentanglement for Constrained Text-to-Image Synthesis** <br>
*Aishwarya Agarwal, Srikrishna Karanam, Balaji Vasan Srinivasan.* <br>
**Image Style Transfer**, Adobe <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2409.02429)] <br>

**Seed-to-Seed: Image Translation in Diffusion Seed Space** <br>
*Or Greenberg, Eran Kishon, Dani Lischinski.* <br>
**Base I2I translation**, The Hebrew University of Jerusalem & GM R&D <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2409.00654)] <br>

**Prompt-Softbox-Prompt: A free-text Embedding Control for Image** <br>
*Yitong Yang, Yinglin Wang, Jing Wang, Tian Zhang.* <br>
**Image Editing**, Shanghai University of Finance and Economics <br>
arXiv 2024. [[PDF](https://arxiv.org/pdf/2408.13623)] <br>

**JieHua Paintings Style Feature Extracting Model using Stable Diffusion with ControlNet** <br>
*Yujia Gu, Haofeng Li, Xinyu Fang, Zihan Peng, Yinan Peng.* <br>
**Image Style Transfer**, California State University et al. <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2408.11744)] <br>

**FAGStyle: Feature Augmentation on Geodesic Surface for Zero-shot Text-guided Diffusion Image Style Transfer** <br>
*Yuexing Han, Liheng Ruan, Bing Wang.* <br>
**Image Style Transfer**, Shanghai University <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2408.10533)] 
[[Github](https://github.com/P2i42/FAGStyle)] <br>

**SurgicaL-CD: Generating Surgical Images via Unpaired Image Translation with Latent Consistency Diffusion Models** <br>
*Danush Kumar Venkatesh, Dominik Rivoir, Micha Pfeiffer, Stefanie Speidel.* <br>
**Medical Image Translation**, NCT/UCC Dresden et al. <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2408.09822)] 
[[Github](https://gitlab.com/nct_tso_public/gan2diffusion)] <br>

**Unpaired Volumetric Harmonization of Brain MRI with Conditional Latent Diffusion** <br>
*Mengqi Wu, Minhui Yu, Shuaiming Jing, Pew-Thian Yap, Zhengwu Zhang, Mingxia Liu.* <br>
**Medical Image Translation**, University of North Carolina <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2408.09315)] 
[[Github](https://github.com/MW1798/HCLD)] <br>

**Conditional Brownian Bridge Diffusion Model for VHR SAR to Optical Image Translation** <br>
*Seon-Hoon Kim, Dae-won Chung.* <br>
**SAR Image Translation**, Korea National University of Science and Technology et al. <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2408.07947)] 
[[Github](https://github.com/egshkim/ConditionalBBDM-for-VHR-SAR-to-Optical)] <br>

**D2Styler: Advancing Arbitrary Style Transfer with Discrete Diffusion Methods** <br>
*Onkar Susladkar, Gayatri Deshmukh, Sparsh Mittal, Parth Shastri.* <br>
**Image Style Transfer**, Indian Institute of Technology et al. <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2408.03558)] 
[[Github](https://github.com/onkarsus13/d2styler)] <br>

**FastEdit: Fast Text-Guided Single-Image Editing via Semantic-Aware Diffusion Fine-Tuning** <br>
*Zhi Chen, Zecheng Zhao, Yadan Luo, Zi Huang.* <br>
**Image Editing**, University of Queensland <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2408.03355)] <br>

**Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention** <br>
*Susung Hong.* <br>
**Else Papers**, Korea University<br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2408.00760)] 
[[Github](https://github.com/susunghong/seg-sdxl)] <br>

**TurboEdit: Text-Based Image Editing Using Few-Step Diffusion Models** <br>
*Gilad Deutch, Rinon Gal, Daniel Garibi, Or Patashnik, Daniel Cohen-Or.* <br>
**Image Editing**, Tel-Aviv University & NVIDIA <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2408.00735)] 
[[Github](https://github.com/GiilDe/turbo-edit)] <br>

**Z\*: Zero-shot Style Transfer via Attention Rearrangement** <br>
*Yingying Deng, Xiangyu He, Fan Tang, Weiming Dong.* <br>
**Image Style Transfer**, Chinese Academy of Sciences <br>
CVPR2024. [[PDF](https://openaccess.thecvf.com/content/CVPR2024/papers/Deng_Z_Zero-shot_Style_Transfer_via_Attention_Reweighting_CVPR_2024_paper.pdf)] 
[[PDF(old)](https://arxiv.org/abs/2311.16491)]
[[Github](https://github.com/HolmesShuan/Zero-shot-Style-Transfer-via-Attention-Rearrangement)] <br>

**A Diffusion Model Translator for Efficient Image-to-Image Translation** <br>
*Mengfei Xia, Yu Zhou, Ran Yi, Yong-Jin Liu, Wenping Wang.* <br>
**Base I2I translation**, Tsinghua University & Shanghai Jiao Tong University & Texas A&M University <br>
TPAMI 2024. [[PDF](https://ieeexplore.ieee.org/abstract/document/10614866)]
[[Github](https://github.com/THU-LYJ-Lab/dmt)] <br>

**InstantStyle-Plus: Style Transfer with Content-Preserving in Text-to-Image Generation** <br>
*Haofan Wang, Peng Xing, Renyuan Huang, Hao Ai, Qixun Wang, Xu Bai.* <br>
**Image Style Transfer**, InstantX Team <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2407.00788)] 
[[Project](instantstyle-plus.github.io)] 
[[Github](https://github.com/instantx-research/instantstyle-plus)] <br>

**SAR to Optical Image Translation with Color Supervised Diffusion Model** <br>
*Xinyu Bai, Feng Xu.* <br>
**SAR Image Translation**, Fudan University <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2407.16921)] <br>

**A Survey of Text Style Transfer: Applications and Ethical Implications** <br>
*Sourabrata Mukherjee, Mateusz Lango, Zdenek Kasner, Ondrej Dušek.* <br>
**Else Papers**, Charles University <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2407.16737)] <br>

**SMooDi: Stylized Motion Diffusion Model** <br>
*Lei Zhong, Yiming Xie, Varun Jampani, Deqing Sun, Huaizu Jiang.* <br>
**Motion Transfer**, Northeastern University & Stability AI & Google Research <br>
ECCV 2024. [[PDF](https://arxiv.org/abs/2407.12783)] 
[[Github](https://github.com/neu-vi/SMooDi)] <br>

**PID: Physics-Informed Diffusion Model for Infrared Image Generation** <br>
*Fangyuan Mao, Jilin Mei, Shun Lu, Fuyang Liu, Liang Chen, Fangzhou Zhao, Yu Hu.* <br>
**Infrared Image Translation**, Chinese Academy of Sciences <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2407.09299)] 
[[Github](https://github.com/fangyuanmao/pid)] <br>

**AirSketch: Generative Motion to Sketch** <br>
*Hui Xian Grace Lim, Xuanming Cui, Yogesh S Rawat, Ser-Nam Lim.* <br>
**Else Papers**, University of Central Florida <br>
NeurIPS 2024. [[PDF](https://arxiv.org/abs/2407.08906)] 
[[Github](https://github.com/hxgr4ce/AirSketch)] <br>

**VisioBlend: Sketch and Stroke-Guided Denoising Diffusion Probabilistic Model for Realistic Image Generation** <br>
*Harshkumar Devmurari, Gautham Kuckian, Prajjwal Vishwakarma, Krunali Vartak.* <br>
**Sketch-to-Image translation**, Vidyavardhini’s College of Engineering and Technology <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2407.05209)] <br>

**Slice-Consistent 3D Volumetric Brain CT-to-MRI Translation with 2D Brownian Bridge Diffusion Model** <br>
*Kyobin Choo, Youngjun Jun, Mijin Yun, Seong Jae Hwang.* <br>
**Medical Image Translation**, Yonsei University <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2407.05059)] 
[[Github](https://github.com/MICV-yonsei/CT2MRI)] <br>

**Every Pixel Has its Moments: Ultra-High-Resolution Unpaired Image-to-Image Translation via Dense Normalization** <br>
*Ming-Yang Ho, Che-Ming Wu, Min-Sheng Wu, Yufeng Jane Tseng.* <br>
**Base I2I translation**, National Taiwan University & Amazon Web Services & aetherAI <br>
ECCV 2024. [[PDF](https://arxiv.org/abs/2407.04245)]
[[Project](https://kaminyou.com/Dense-Normalization/)] 
[[Github](https://github.com/Kaminyou/Dense-Normalization)] <br>

**Frequency-Controlled Diffusion Model for Versatile Text-Guided Image-to-Image Translation** <br>
*Xiang Gao, Zhengbo Xu, Junhan Zhao, Jiaying Liu.* <br>
**Base I2I translation**, Peking University <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2407.03006)] 
[[Github](https://github.com/xianggao1102/fcdiffusion)] <br>

**MUMU: Bootstrapping Multimodal Image Generation from Text-to-Image Data** <br>
*William Berman, Alexander Peysakhovich.* <br>
**Else Papers**, Residence Sutter Hill Ventures <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2406.18790)] <br>

**Regularized Distribution Matching Distillation for One-step Unpaired Image-to-Image Translation** <br>
*Denis Rakitin, Ivan Shchekotov, Dmitry Vetrov.* <br>
**Base I2I translation**, HSE University <br>
ICML 2024 workshop. [[PDF](https://arxiv.org/abs/2406.14762)] <br>

**AnyTrans: Translate AnyText in the Image with Large Scale Models** <br>
*Zhipeng Qian, Pei Zhang, Baosong Yang, Kai Fan, Yiwei Ma, Derek F. Wong, Xiaoshuai Sun, Rongrong Ji.* <br>
**Else Papers**, Xiamen University & Alibaba Group Inc <br>
EMNLP 2024. [[PDF](https://arxiv.org/abs/2406.11432)] 
[[Github](https://github.com/qzp2018/AnyTrans)] <br>

**Rethinking Score Distillation as a Bridge Between Image Distributions** <br>
*David McAllister, Songwei Ge, Jia-Bin Huang, David W. Jacobs, Alexei A. Efros, Aleksander Holynski, Angjoo Kanazawa.* <br>
**Else Papers**, UC Berkeley & University of Maryland <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2406.09417)] 
[[Project](https://sds-bridge.github.io/)] 
[[Github](https://github.com/davidmcall/SDS-Bridge)] <br>

**PASTA: Pathology-Aware MRI to PET Cross-Modal Translation with Diffusion Models** <br>
*Yitong Li, Igor Yakushev, Dennis M. Hedderich, Christian Wachinger.* <br>
**Medical Image Translation**, Technical University of Munich & MCML <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2405.16942)]
[[Github](https://github.com/ai-med/pasta)] <br>

**Diffusion Bridge Implicit Models** <br>
*Kaiwen Zheng, Guande He, Jianfei Chen, Fan Bao, Jun Zhu.* <br>
**Base I2I translation**,  Tsinghua University & Shengshu Technology <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2405.15885)] 
[[Github](https://github.com/thu-ml/DiffusionBridge)] <br>

**Fast-DDPM: Fast Denoising Diffusion Probabilistic Models for Medical Image-to-Image Generation** <br>
*Hongxu Jiang, Muhammad Imran, Linhai Ma, Teng Zhang, Yuyin Zhou, Muxuan Liang, Kuang Gong, Wei Shao.* <br>
**Medical Image Translation**, University of Florida & University of California <br>
arXiv 2024, [[PDF](https://arxiv.org/abs/2405.14802)]
[[Github](https://github.com/mirthai/fast-ddpm)] <br>

**Self-Consistent Recursive Diffusion Bridge for Medical Image Translation** <br>
*Jose-Luis Poza-Lujan, Pedro Uribe-Chavert, Juan-Luis Posadas-Yagüe.* <br>
**Medical Image Translation**, Bilkent University & University of Illinois Urbana-Champaign <br>
arXiv 2024, [[PDF](http://arxiv.org/abs/2405.06789v1)] 
[[PDF(old)](https://arxiv.org/abs/2405.06789)] 
[[Github](https://github.com/icon-lab/SelfRDB)] <br>

**GeoDiffuser: Geometry-Based Image Editing with Diffusion Models** <br>
*Rahul Sajnani, Jeroen Vanbaar, Jie Min, Kapil Katyal, Srinath Sridhar.* <br>
**Image Editing**, Brown University & Amazon Robotics <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2404.14403)] <br>

**F2FLDM: Latent Diffusion Models with Histopathology Pre-Trained Embeddings for Unpaired Frozen Section to FFPE Translation** <br>
*Man M. Ho, Shikha Dubey, Yosep Chong, Beatrice Knudsen, Tolga Tasdizen.* <br>
**Medical Image Translation**, University of Utah & The Catholic University of Korea College of Medicine <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2404.12650)]
[[Github](https://github.com/minhmanho/f2f_ldm)] <br>

**Towards Highly Realistic Artistic Style Transfer via Stable Diffusion with Step-aware and Layer-aware Prompt Inversion** <br>
*Zhanjie Zhang, Quanwei Zhang, Huaizhong Lin, Wei Xing, Juncheng Mo, Shuaicheng Huang, Jinheng Xie, Guangyuan Li, Junsheng Luan, Lei Zhao, Dalong Zhang, Lixia Chen.* <br>
**Image Style Transfer**, Zhejiang University <br>
IJCAI 2024. [[PDF](https://arxiv.org/abs/2404.11474)]
[[Github](https://github.com/jamie-cheung/lsast)] <br>

**Optical Image-to-Image Translation Using Denoising Diffusion Models: Heterogeneous Change Detection as a Use Case** <br>
*Joao Gabriel Vinholi, Marco Chini, Anis Amziane, Renato Machado, Danilo Silva, Patrick Matgen.* <br>
**Base I2I translation**, Luxembourg Institute of Science and Technology <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2404.11243)] <br>

**MultiColor: Image Colorization by Learning from Multiple Color Spaces** <br>
*Xiangcheng Du, Zhao Zhou, Xingjiao Wu, Yanlong Wang, Zhuoyao Wang, Yingbin Zheng, Cheng Jin.* <br>
**Image Colorization**, Fudan University <br>
ACMMM 2024. [[PDF](https://openreview.net/pdf?id=Zo4P2F7xLY)] <br>

**Tackling Structural Hallucination in Image Translation with Local Diffusion** <br>
*Seunghoi Kim, Chen Jin, Tom Diethe, Matteo Figini, Henry F. J. Tregidgo, Asher Mullokandov, Philip Teare, Daniel C. Alexander.* <br>
**Base I2I translation**, University College London <br>
ECCV 2024. [[PDF](https://arxiv.org/abs/2404.05980)] 
[[Github](https://github.com/edshkim98/LocalDiffusion-Hallucination)] <br>

**Automatic Controllable Colorization via Imagination** <br>
*Xiaoyan Cong, Yue Wu, Qifeng Chen, Chenyang Lei.* <br>
**Image Colorization**, CAIR, HKISI-CAS et al. <br>
CVPR 2024. [[PDF](https://arxiv.org/abs/2404.05661)] 
[[Project](https://xy-cong.github.io/imagine-colorization/)] 
[[Github](https://github.com/xy-cong/imagine-colorization)] <br>

**InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation** <br>
*Haofan Wang, Matteo Spinelli, Qixun Wang, Xu Bai, Zekui Qin, Anthony Chen.* <br>
**Image Style Transfer**, InstantX Team <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2404.02733)] 
[[Project](https://instantstyle.github.io)] 
[[Github](https://github.com/instantX-research/InstantStyle)]<br>

**DEADiff: An Efficient Stylization Diffusion Model with Disentangled Representations** <br>
*Tianhao Qi, Shancheng Fang, Yanze Wu, Hongtao Xie, Jiawei Liu, Lang Chen, Qian He, Yongdong Zhang.* <br>
**Image Style Transfer**, University of Science and Technology of China & ByteDance <br>
CVPR 2024. [[PDF](https://arxiv.org/abs/2403.06951)]
[[PDF2](https://openaccess.thecvf.com/content/CVPR2024/papers/Qi_DEADiff_An_Efficient_Stylization_Diffusion_Model_with_Disentangled_Representations_CVPR_2024_paper.pdf)]
[[Project](https://tianhao-qi.github.io/DEADiff/)] 
[[Github](https://github.com/bytedance/DEADiff)] <br>

**One-Shot Structure-Aware Stylized Image Synthesis** <br>
*Hansam Cho, Jonghyun Lee, Seunggyu Chang, Yonghyun Jeong.* <br>
**Image Style Transfer**, Korea University & NAVER Cloud <br>
CVPR 2024. [[PDF](https://arxiv.org/abs/2402.17275v1)] 
[[Github](https://github.com/hansam95/osasis)] <br>

**UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models** <br>
*Yihua Zhang, Yimeng Zhang, Yuguang Yao, Jinghan Jia, Jiancheng Liu, Xiaoming Liu, Sijia Liu.* <br>
**Image Style Transfer**, Michigan State University & IBM Research & Cisco Research <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2402.11846)]
[[Github](https://github.com/OPTML-Group/UnlearnCanvas)] <br>

**Control Color: Multimodal Diffusion-based Interactive Image Colorization** <br>
*Zhexin Liang, Zhaochen Li, Shangchen Zhou, Chongyi Li, Chen Change Loy.* <br>
**Image Colorization**, Nanyang Technological University <br>
Arxiv 2024, [[PDF](https://arxiv.org/abs/2402.10855)] 
[[Github](https://github.com/ZhexinLiang/Control-Color)] <br>

**Diffusion Model Compression for Image-to-Image Translation** <br>
(Task-Oriented Diffusion Model Compression) <br>
*Geonung Kim, Beomsu Kim, Eunhyeok Park, Sunghyun Cho.* <br>
**Else Papers**, POSTECH <br>
ACCV 2024. [[PDF](https://arxiv.org/abs/2401.17547)] 
[[Project](https://kimgeonung.github.io/id-compression/)] 
[[Github](https://github.com/KIMGEONUNG/ID-compression)] <br>

**Image Translation as Diffusion Visual Programmers** <br>
*Cheng Han, James C. Liang, Qifan Wang, Majid Rabbani, Sohail Dianat, Raghuveer Rao, Ying Nian Wu, Dongfang Liu.* <br>
**Base I2I translation**, Rochester Institute of Technology & Meta AI <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2401.09742)] <br>

**HiCAST: Highly Customized Arbitrary Style Transfer with Adapter Enhanced Diffusion Models** <br>
*Hanzhang Wang, Haoran Wang, Jinze Yang, Zhongrui Yu, Zeke Xie, Lei Tian, Xinyan Xiao, Junjun Jiang, Xianming Liu, Mingming Sun.* <br>
**Image Style Transfer**, Harbin Institute of Technology & Baidu <br>
arXiv 2024. [[PDF](https://arxiv.org/abs/2401.05870)]
[[Github](https://github.com/wd1511/HiCAST)] <br>

**Adaptive latent diffusion model for 3d medical image to image translation: Multi-modal magnetic resonance imaging study** <br>
*Jonghun Kim, Hyunjin Park.* <br>
**Medical Image Translation**, Sungkyunkwan University <br>
WACV 2024. [[Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Kim_Adaptive_Latent_Diffusion_Model_for_3D_Medical_Image_to_Image_WACV_2024_paper.pdf)] 
[[Github](https://github.com/jongdory/aldm)] <br>

**Artfusion: A Diffusion Model-Based Style Synthesis Framework for Portraits** <br>
*Hyemin Yang, Heekyung Yang, Kyungha Min.* <br>
**Image Style Transfer**, Sangmyung University <br>
Electronics 2024. [[Paper](https://www.mdpi.com/2079-9292/13/3/509)] <br>

**MirrorDiffusion: Stabilizing Diffusion Process in Zero-shot Image Translation by Prompts Redescription and Beyond** <br>
*Yupei Lin, Xiaoyu Xian, Yukai Shi, Liang Lin.* <br>
**Base I2I translation**, Guangdong University of Technology & CRRC Academy & Sun Yat-sen University <br>
IEEE Signal Processing Letters(SPL) 2024. [[PDF](https://arxiv.org/abs/2401.03221)]
[[Project](https://mirrordiffusion.github.io)] 
[[Github](https://github.com/MirrorDiffusion/MirrorDiffusion)] <br>

**Style Injection in Diffusion: A Training-free Approach for Adapting Large-scale Diffusion Models for Style Transfer** <br>
*Jiwoo Chung, Sangeek Hyun, Jae-Pil Heo.* <br>
**Image Style Transfer**, Sungkyunkwan University <br>
CVPR 2024. [[PDF](https://arxiv.org/abs/2312.09008)]
[[Github](https://github.com/jiwoogit/StyleID)] <br>

**ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs** <br>
*Viraj Shah, Nataniel Ruiz, Forrester Cole, Erika Lu, Svetlana Lazebnik, Yuanzhen Li, Varun Jampani.* <br>
**Image Style Transfer**, Google Research & UIUC <br>
ECCV 2024. [[PDF](https://arxiv.org/abs/2311.13600)]
[[Project](https://ziplora.github.io)] 
[[Github](https://github.com/mkshing/ziplora-pytorch)] <br>

**Cross-Image Attention for Zero-Shot Appearance Transfer** <br>
*Yuval Alaluf, Daniel Garibi, Or Patashnik, Hadar Averbuch-Elor, Daniel Cohen-Or.* <br>
**Image Style Transfer**, Tel Aviv University <br>
SIGGRAPH 2024. [[PDF](https://arxiv.org/abs/2311.03335)]
[[Project](https://garibida.github.io/cross-image-attention/)] 
[[Github](https://github.com/garibida/cross-image-attention)] <br>

## 2023

**Conditional diffusion for SAR to optical image translation** <br>
*Xinyu Bai, Xinyang Pu, Feng Xu.* <br>
**SAR Image Translation**, Fudan University <br>
IEEE Geoscience and Remote Sensing Letters 2023 [[PDF](https://ieeexplore.ieee.org/document/10330015)]
[[Github](https://github.com/Coordi777/Conditional-Diffusion-for-SAR-to-Optical-Image-Translation)] <br>

**Diffusion Cocktail: Fused Generation from Diffusion Models** <br>
*Haoming Liu, Yuanhe Guo, Shengjie Wang, Hongyi Wen.* <br>
**Image Style Transfer**, NYU Shanghai <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2312.08873)]
[[Project](https://maps-research.github.io/Ditail/)]
[[Github](https://github.com/MAPS-research/Ditail)] <br>

**Diffusing Colors: Image Colorization with Text Guided Diffusion** <br>
*Nir Zabari, Aharon Azulay, Alexey Gorkor, Tavi Halperin, Ohad Fried.* <br>
**Image Colorization**, Lightricks <br>
SIGGRAPH Asia 2023. [[PDF](https://arxiv.org/abs/2312.04145)] 
[[Project](https://aharonazulay.github.io/project_page_colorization/)] <br>

**Personalized Face Inpainting with Diffusion Models by Parallel Visual Attention** <br>
*Jianjin Xu, Saman Motamed, Praneetha Vaddamanu, Chen Henry Wu, Christian Haene, Jean-Charles Bazin, Fernando de la Torre.* <br>
**Image Editing**, Carnegie Mellon University <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2312.03556)] <br>

**Open-DDVM: A Reproduction and Extension of Diffusion Model for Optical Flow Estimation** <br>
*Qiaole Dong, Bo Zhao, Yanwei Fu.* <br>
**Else Papers**, Fudan University <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2312.01746)] 
[[Github](https://github.com/dqiaole/flowdiffusion_pytorch)] <br>

**S2ST: Image-to-Image Translation in the Seed Space of Latent Diffusion** <br>
*Or Greenberg, Eran Kishon, Dani Lischinski.* <br>
**Base I2I translation**, GM R&D & Hebrew University <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2312.00116)] <br>

**CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for Image Manipulation** <br>
*Sihan Xu, Ziqiao Ma, Yidong Huang, Honglak Lee, Joyce Chai.* <br>
**Image Manipulation**, University of Michigan & LG AI Research <br>
NeurIPS 2023. [[PDF](https://arxiv.org/abs/2310.13165)] 
[[Github](https://github.com/sled-group/cyclenet)] <br>

**Latent Diffusion Counterfactual Explanations** <br>
*Karim Farid, Simon Schrodi, Max Argus, Thomas Brox.* <br>
**Base I2I translation**, University of Freiburg <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2310.06668)] 
[[Github](https://github.com/lmb-freiburg/ldce)] <br>

**MedPrompt: Cross-Modal Prompting for Multi-Task Medical Image Translation** <br>
*Xuhang Chen, Chi-Man Pun, Shuqiang Wang.* <br>
**Medical Image Translation**, Shenzhen Institutes of Advanced Technology & University of Macau <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2310.02663)] <br>

**Steered Diffusion: A Generalized Framework for Plug-and-Play Conditional Image Synthesis** <br>
*Nithin Gopalakrishnan Nair, Anoop Cherian, Suhas Lohit, Ye Wang, Toshiaki Koike-Akino, Vishal M. Patel, Tim K. Marks.* <br>
**Base I2I translation**, Johns Hopkins University <br>
ICCV 2023. [[PDF](https://arxiv.org/abs/2310.00224)] 
[[Github](https://github.com/merlresearch/SteeredDiffusion)] <br>

**Denoising Diffusion Bridge Models** <br>
*Linqi Zhou, Aaron Lou, Samar Khanna, Stefano Ermon.* <br>
**Base I2I translation**, Stanford University <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2309.16948)] 
[[Github-1](https://github.com/alexzhou907/DDBM)] 
[[Github-2](https://github.com/galaxygliese/Latent-DDBM)] <br>

**Multiple Noises in Diffusion Model for Semi-Supervised Multi-Domain Translation** <br>
*Tsiry Mayet, Simon Bernard, Clement Chatelain, Romain Herault.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2309.14394)] <br>

**Cartoondiff: Training-free Cartoon Image Generation with Diffusion Transformer Models** <br>
*Feihong He, Gang Li, Lingyu Si, Leilei Yan, Shimeng Hou, Hongwei Dong, Fanzhang Li.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2309.08251)] 
[[Project](https://cartoondiff.github.io)] 
[[Github](https://github.com/CartoonDiff/CartoonDiff)] <br>

**DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion Models** <br>
*Namhyuk Ahn, Junsoo Lee, Chunggi Lee, Kunhee Kim, Daesik Kim, Seung-Hun Nam, Kibeom Hong.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2309.06933)] 
[[Project](https://nmhkahn.github.io/dreamstyler/)] 
[[Github](https://github.com/nmhkahn/dreamstyler)] <br>

**PAI-Diffusion: Constructing and Serving a Family of Open Chinese Diffusion Models for Text-to-image Synthesis on the Cloud** <br>
*Chengyu Wang, Zhongjie Duan, Bingyan Liu, Xinyi Zou, Cen Chen, Kui Jia, Jun Huang.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2309.05534)] <br>

**Create Your World: Lifelong Text-to-Image Diffusion** <br>
*Gan Sun, Wenqi Liang, Jiahua Dong, Jun Li, Zhengming Ding, Yang Cong.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2309.04430)] <br>

**Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption** <br>
*Teng Hu, Jiangning Zhang, Liang Liu, Ran Yi, Siqi Kou, Haokun Zhu, Xu Chen, Yabiao Wang, Chengjie Wang, Lizhuang Ma.* <br>
ICCV 2023. [[PDF](https://arxiv.org/abs/2309.03729)] 
[[Github](https://github.com/sjtuplayer/few-shot-diffusion)] <br>

**StyleAdapter: A Single-Pass LoRA-Free Model for Stylized Image Generation** <br>
*Zhouxia Wang, Xintao Wang, Liangbin Xie, Zhongang Qi, Ying Shan, Wenping Wang, Ping Luo.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2309.01770)] <br>

**Latent Painter** <br>
*Shih-Chieh Su.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2308.16490)] <br>

**ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer** <br>
*Zachary Horvitz, Ajay Patel, Chris Callison-Burch, Zhou Yu and Kathleen McKeown.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2308.15459)] 
[[Github](https://github.com/zacharyhorvitz/ParaGuide)] <br>

**Zero-shot Inversion Process for Image Attribute Editing with Diffusion Models** <br>
*Zhanbo Feng, Zenan Ling, Ci Gong, Feng Zhou, Jie Li, Robert C. Qiu.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2308.15854)] <br>

**Pixel-Aware Stable Diffusion for Realistic Image Super-resolution and Personalized Stylization** <br>
*Tao Yang, Peiran Ren, Xuansong Xie, Lei Zhang.* <br>
arXiv 2023.[[PDF](https://arxiv.org/abs/2308.14469)] 
[[Github](https://github.com/yangxy/PASD)] <br>

**DiffI2I: Efficient Diffusion Model for Image-to-Image Translation** <br>
*Bin Xia, Yulun Zhang, Shiyin Wang, Yitong Wang, Xinglong Wu, Yapeng Tian, Wenming Yang, Radu Timotfe, Luc Van Gool.* <br>
arXiv 2023. [[PDF](http://arxiv.org/abs/2308.13767v1)] <br>

**Diffusion-based Image Translation with Label Guidance for Domain Adaptive Semantic Segmentation** <br>
*Duo Peng, Ping Hu, Qiuhong Ke, Jun Liu.* <br>
ICCV 2023. [[PDF](https://arxiv.org/abs/2308.12350)] 
[[Github](https://github.com/xXCoffeeColaXc/DiffusionBasedImageTranlationWithGradientGuidance)] <br>

**SSMG: Spatial-Semantic Map Guided Diffusion Model for Free-form Layout-to-Image Generation** <br>
*Chengyou Jia, Minnan Luo, Zhuohang Dang, Guang Dai, Xiaojun Chang, Mengmeng Wang, Jingdong Wang.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2308.10156)] <br>

**MeDM: Mediating Image Diffusion Models for Video-to-Video Translation with Temporal Correspondence Guidance** <br>
*Ernie Chu, Tzuhsuan Huang, Shuo-Yen Lin, Jun-Cheng Chen.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2308.10079)] 
[[Project](https://medm2023.github.io/)] 
[[Github](https://github.com/jwliao1209/diffqrcode)] <br>

**StyleDiffusion: Controllable Disentangled Style Transfer via Diffusion Models** <br>
*Zhizhong Wang, Lei Zhao, Wei Xing.* <br>
**Image Style Transfer**, Zhejiang University <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2308.07863)] 
[[Github](https://github.com/rafaelheid-it/StyleDiffusion)] <br>

**Inversion-by-Inversion: Exemplar-based Sketch-to-Photo Synthesis via Stochastic Differential Equations without Training** <br>
*Ximing Xing, Chuang Wang, Haitao Zhou, Zhihao Hu, Chongxuan Li, Dong Xu, Qian Yu.* <br>
**Sketch-to-Image translation**, Beihang University & Renmin University of China & The University of Hong Kong <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2308.07665)] 
[[Project](https://ximinng.github.io/inversion-by-inversion-project/)] 
[[Github](https://github.com/ximinng/inversion-by-inversion)] <br>

**Taming the Power of Diffusion Models for High-Quality Virtual Try-On with Appearance Flow** <br>
*Junhong Gou, Siyu Sun, Jianfu Zhang, Jianlou Si, Chen Qian, Liqing Zhang.* <br>
**virtual try-on**, Shanghai Jiao Tong University & SenseTime Research<br>
ACMMM 2023. [[PDF](https://arxiv.org/abs/2308.06101)]
[[Github](https://github.com/bcmi/DCI-VTON-Virtual-Try-On)] <br>

**Head Rotation in Denoising Diffusion Models** <br>
*Andrea Asperti, Gabriele Colasuonno, Antonio Guerra.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2308.06057)] 
[[Github](https://github.com/asperti/head-rotation)] <br>

**Photorealistic and Identity-Preserving Image-Based Emotion Manipulation with Latent Diffusion Models** <br>
*Ioannis Pikoulis, Panagiotis P. Filntisis, Petros Maragos.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2308.03183)] 
[[Github](https://github.com/giannispikoulis/dsml-thesis)] <br>

**SDDM: Score-Decomposed Diffusion Models on Manifolds for Unpaired Image-to-Image Translation** <br>
*Shikun Sun, Longhui Wei, Junliang Xing, Jia Jia, Qi Tian.* <br>
ICML 2023. [[PDF](https://arxiv.org/abs/2308.02154)] <br>

**Interpolating between Images with Diffusion Models** <br>
*Clinton J. Wang, Polina Golland.* <br>
ICML Workshop 2023. [[PDF](https://arxiv.org/abs/2307.12560)] 
[[Project](https://clintonjwang.github.io/interpolation)] 
[[Github](https://github.com/clintonjwang/ControlNet)] <br>

**TF-ICON: Diffusion-Based Training-Free Cross-Domain Image Composition** <br>
*Shilin Lu, Yanzhu Liu, Adams Wai-Kin Kong.* <br>
ICCV 2023. [[PDF](https://arxiv.org/abs/2307.12493)] 
[[Github](https://github.com/Shilin-LU/TF-ICON)] <br>

**DiffuseGAE: Controllable and High-fidelity Image Manipulation from Disentangled Representation** <br>
*Yipeng Leng, Qiangjuan Huang, Zhiyuan Wang, Yangyang Liu, Haoyu Zhang.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2307.05899)] 
[[Github](https://github.com/ecai2023/DiffuseGAE)] <br>

**DIFF-NST: Diffusion Interleaving For deFormable Neural Style Transfer** <br>
*Dan Ruta, Gemma Canet Tarrés, Andrew Gilbert, Eli Shechtman, Nicholas Kolkin, John Collomosse.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2307.04157)] <br>

**Applying a Color Palette with Local Control using Diffusion Models** <br>
*Vaibhav Vavilala, David Forsyth.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2307.02698)] <br>

**DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models** <br> 
*Chong Mou, Xintao Wang, Jiechong Song, Ying Shan, Jian Zhang.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2307.02421)] 
[[Project](https://mc-e.github.io/project/DragonDiffusion/)] 
[[Github-1](https://github.com/MC-E/DragonDiffusion)] 
[[Github-2](https://github.com/stroopwafl/dragon_diffusion)] <br>

**DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing** <br>
*Yujun Shi, Chuhui Xue, Jiachun Pan, Wenqing Zhang, Vincent Y. F. Tan, Song Bai.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2306.14435)] 
[[Github-1](https://github.com/Yujun-Shi/DragDiffusion)] 
[[Github-2](https://github.com/JiauZhang/DragDiffusion)] <br>

**ArtFusion: Controllable Arbitrary Style Transfer using Dual Conditional Latent Diffusion Models** <br>
*Dar-Yen Chen.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2306.09330)] 
[[Github](https://github.com/ChenDarYen/ArtFusion)] <br>

**Improving Diffusion-based Image Translation using Asymmetric Gradient Guidance** <br>
*Gihyun Kwon, Jong Chul Ye.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2306.04396)] 
[[Github](https://github.com/submissionanon18/agg)] <br>

**Interpretable Style Transfer for Text-to-Speech with ControlVAE and Diffusion Bridge** <br>
*Wenhao Guan, Tao Li, Yishuang Li, Hukai Huang, Qingyang Hong, Lin Li.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2306.04301)] <br>

**Fine-grained Text Style Transfer with Diffusion-Based Language Models** <br>
*Yiwei Lyu, Tiange Luo, Jiacheng Shi, Todd C. Hollon, Honglak Lee.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2305.19512)] 
[[Github](https://github.com/lvyiwei1/diffuseq_styleptb)] <br>

**DiffSketching: Sketch Control Image Synthesis with Diffusion Models** <br>
*Qiang Wang, Di Kong, Fengyin Lin, Yonggang Qi.* <br>
**Sketch-to-Image translation**, Beijing University of Posts and Telecommunications <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2305.18812)] 
[[Github](https://github.com/XDUWQ/DiffSketching)] <br>

**Real-World Image Variation by Aligning Diffusion Inversion Chain** <br>
*Yuechen Zhang, Jinbo Xing, Eric Lo, Jiaya Jia* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2305.18729)] 
[[Project](https://rival-diff.github.io)] 
[[Github](https://github.com/JulianJuaner/RIVAL)] <br>

**Photoswap: Personalized Subject Swapping in Images** <br>
*Jing Gu, Yilin Wang, Nanxuan Zhao, Tsu-Jui Fu, Wei Xiong, Qing Liu, Zhifei Zhang, He Zhang, Jianming Zhang, HyunJoon Jung, Xin Eric Wang.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2305.18286)] 
[[Project](https://photoswap.github.io/)] 
[[Github](https://github.com/eric-ai-lab/photoswap)] <br>

**Diversify Your Vision Datasets with Automatic Diffusion-Based Augmentation** <br>
*Lisa Dunlap, Alyssa Umino, Han Zhang, Jiezhi Yang, Joseph E. Gonzalez, Trevor Darrell.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2305.16289)] 
[[Github](https://github.com/lisadunlap/ALIA)] <br>

**ProSpect: Expanded Conditioning for the Personalization of Attribute-aware Image Generation** <br>
*Yuxin Zhang, Weiming Dong, Fan Tang, Nisha Huang, Haibin Huang, Chongyang Ma, Tong-Yee Lee, Oliver Deussen, Changsheng Xu.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2305.16225)] 
[[Github](https://github.com/zyxElsa/ProSpect)] <br>

**Unpaired Image-to-Image Translation via Neural Schrödinger Bridge** <br>
*Beomsu Kim, Gihyun Kwon, Kwanyoung Kim, Jong Chul Ye.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2305.15086)] 
[[Github](https://github.com/cyclomon/UNSB)] <br>

**SAR-to-Optical Image Translation via Thermodynamics-inspired Network** <br>
*Mingjin Zhang, Jiamin Xu, Chengyu He, Wenteng Shang, Yunsong Li, Xinbo Gao.* <br>
**SAR Image Translation**, Xidian University <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2305.13839)] <br>

**Null-text Guidance in Diffusion Models is Secretly a Cartoon-style Creator** <br>
*Jing Zhao, Heliang Zheng, Chaoyue Wang, Long Lan, Wanrong Huang, Wenjing Yang.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2305.06710)] 
[[Project](https://nulltextforcartoon.github.io/)] 
[[Github](https://github.com/NullTextforCartoon/NullTextforCartoon)] <br>

**ReGeneration Learning of Diffusion Models with Rich Prompts for Zero-Shot Image Translation** <br>
*Yupei Lin, Sen Zhang, Xiaojun Yang, Xiao Wang, Yukai Shi.* <br>
arXiv 2023. [[PDF](http://arxiv.org/abs/2305.04651v1)] 
[[Project](https://yupeilin2388.github.io/publication/ReDiffuser)] <br> 

**Hierarchical Diffusion Autoencoders and Disentangled Image Manipulation** <br>
*Zeyu Lu, Chengyue Wu, Xinyuan Chen, Yaohui Wang, Yu Qiao, Xihui Liu.* <br>
WACV 2023. [[PDF](https://arxiv.org/abs/2304.11829)] 
[[Github](https://github.com/whlzy/Hierarchical-Diffusion-Autoencoders)] <br>

**Improved Diffusion-based Image Colorization via Piggybacked Models** <br>
*Hanyuan Liu, Jinbo Xing, Minshan Xie, Chengze Li, Tien-Tsin Wong.* <br>
**Image Colorization**, The Chinese University of Hong Kong & Caritas Institute of Higher Education <br>
arXiv 2023. [[PDF](https://arxiv.org/pdf/2304.11105)] 
[[Project](https://piggyback-color.github.io)] 
[[Github](https://github.com/hyliu/piggyback-color)] <br>

**Reference-based Image Composition with Sketch via Structure-aware Diffusion Model** <br>
*Kangyeol Kim, Sunghyun Park, Junsoo Lee, Jaegul Choo.* <br>
**Sketch-to-Image translation**, KAIST & Letsur Inc. & Naver Webtoon <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2304.09748)] 
[[Github](https://github.com/kangyeolk/paint-by-sketch)] <br>

**Face Animation with an Attribute-Guided Diffusion Model** <br>
*Bohan Zeng, Xuhui Liu, Sicheng Gao, Boyu Liu, Hong Li, Jianzhuang Liu, Baochang Zhang.* <br>
arXiv 2023. [[PDF](http://arxiv.org/abs/2304.03199v1)] [[PDF(old)](https://arxiv.org/abs/2304.03199)]
[[Github](https://github.com/zengbohan0217/fadm)] <br>

**PAIR-Diffusion: A Comprehensive Multimodal Object-Level Image Editor** <br>
*Vidit Goel, Elia Peruzzo, Yifan Jiang, Dejia Xu, Xingqian Xu, Nicu Sebe, Trevor Darrell, Zhangyang Wang, Humphrey Shi.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2303.17546)] 
[[Github](https://github.com/Picsart-AI-Research/PAIR-Diffusion)] <br>

**StyleDiffusion: Prompt-Embedding Inversion for Text-Based Editing** <br>
*Senmao Li, Joost van de Weijer, Taihang Hu, Fahad Shahbaz Khan, Qibin Hou, Yaxing Wang, Jian Yang.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2303.15649)] 
[[Github](https://github.com/sen-mao/StyleDiffusion)] <br>

**Training-free Style Transfer Emerges from h-space in Diffusion models** <br>
*Jaeseok Jeong, Mingi Kwon, Youngjung Uh.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2303.15403)] 
[[Project](https://curryjung.github.io/DiffStyle/)] 
[[Github](https://github.com/curryjung/DiffStyle_official)] <br>

**Diffusion-based Target Sampler for Unsupervised Domain Adaptation** <br>
*Yulong Zhang, Shuhao Chen, Yu Zhang, Jiangang Lu.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2303.12724)] <br>

**Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer** <br>
*Serin Yang, Hyunmin Hwang, Jong Chul Ye.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2303.08622)] 
[[Github](https://github.com/ouhenio/text-guided-diffusion-style-transfer)] <br>

**StyO: Stylize Your Face in Only One-Shot** <br>
*Bonan Li, Zicheng Zhang, Xuecheng Nie, Congying Han, Yinhan Hu, Tiande Guo.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2303.03231)] 
[[Github](https://github.com/JiauZhang/StyO)] <br>

**DiffFashion: Reference-based Fashion Design with Structure-aware Transfer by Diffusion Models** <br>
*Shidong Cao, Wenhao Chai, Shengyu Hao, Yanting Zhang, Hangyue Chen, Gaoang Wang.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2302.06826)] 
[[Github](https://github.com/Rem105-210/DiffFashion)] <br>

**I2SB: Image-to-Image Schrödinger Bridge** <br>
*Guan-Horng Liu, Arash Vahdat, De-An Huang, Evangelos A. Theodorou, Weili Nie, Anima Anandkumar.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2302.05872)] 
[[Project](https://i2sb.github.io/)] 
[[Github](https://github.com/NVlabs/I2SB)] <br>

**Zero-shot-Learning Cross-Modality Data Translation Through Mutual Information Guided Stochastic Diffusion** <br>
*Zihao Wang, Yingyu Yang, Maxime Sermesant, Hervé Delingette, Ona Wu.* <br>
arXiv 2023. [[PDF](https://arxiv.org/abs/2301.13743)] <br>

**ControlStyle: Text-Driven Stylized Image Generation Using Diffusion Priors** <br>
*Jingwen Chen, Yingwei Pan, Ting Yao, Tao Mei.* <br>
ACMMM 2023. [[PDF](https://arxiv.org/abs/2311.05463)] 
[[Github](https://github.com/winnechan/ControlStyle)] <br>

**General Image-to-Image Translation with One-Shot Image Guidance** <br>
*Bin Cheng, Zuhao Liu, Yunbo Peng, Yue Lin.* <br>
ICCV 2023. [[PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_General_Image-to-Image_Translation_with_One-Shot_Image_Guidance_ICCV_2023_paper.pdf)] 
[[PDF(old)](https://arxiv.org/abs/2307.14352)] 
[[Github](https://github.com/crystalneuro/visual-concept-translator)] <br>

**MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation** <br>
*Omer Bar-Tal, Lior Yariv, Yaron Lipman, Tali Dekel.* <br>
ICML 2023.[[PDF](https://openreview.net/pdf?id=D4ajVWmgLB)] 
[[Github](https://github.com/omerbt/MultiDiffusion)] <br>

**InfoDiffusion: Representation Learning Using Information Maximizing Diffusion Models** <br>
*Yingheng Wang, Yair Schiff, Aaron Gokaslan, Weishen Pan, Fei Wang, Christopher De Sa, Volodymyr Kuleshov.* <br>
ICML 2023. [[PDF](https://arxiv.org/abs/2306.08757)] 
[[Github](https://github.com/gregversteeg/InfoDiffusionSimple)] <br>

**TryOnDiffusion: A Tale of Two UNets** <br>
*Luyang Zhu, Dawei Yang, Tyler Zhu, Fitsum Reda, William Chan, Chitwan Saharia, Mohammad Norouzi, Ira Kemelmacher-Shlizerman.* <br>
CVPR 2023. [[PDF](https://arxiv.org/abs/2306.08276)] 
[[Github](https://github.com/fashn-AI/tryondiffusion)] <br>

**DiffusionRig: Learning Personalized Priors for Facial Appearance Editing** <br>
*Zheng Ding, Xuaner Zhang, Zhihao Xia, Lars Jebe, Zhuowen Tu, Xiuming Zhang.* <br>
CVPR 2023. [[PDF](https://arxiv.org/abs/2304.06711)] 
[[Project](https://diffusionrig.github.io/)] 
[[Github](https://github.com/adobe-research/diffusion-rig)] <br>

**InstructPix2Pix: Learning to Follow Image Editing Instructions** <br>
*Tim Brooks, Aleksander Holynski, Alexei A. Efros.*   <br>
CVPR 2023. [[PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf)] 
[[GitHub](https://github.com/timothybrooks/instruct-pix2pix)] <br>

**EDICT: Exact Diffusion Inversion via Coupled Transformations** <br>
*Bram Wallace, Akash Gokul, Nikhil Naik.* <br>
CVPR 2023. [[PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Wallace_EDICT_Exact_Diffusion_Inversion_via_Coupled_Transformations_CVPR_2023_paper.pdf)] 
[[Github](https://github.com/salesforce/edict)] <br>

**High-Fidelity Guided Image Synthesis with Latent Diffusion Models** <br>
*Jaskirat Singh, Stephen Gould, Liang Zheng.* <br>
CVPR 2023. [[PDF](https://arxiv.org/abs/2211.17084)] 
[[Github](https://1jsingh.github.io/gradop)] <br>

**Inversion-Based Creativity Transfer with Diffusion Models** <br>
*Yuxin Zhang, Nisha Huang, Fan Tang, Haibin Huang, Chongyang Ma, Weiming Dong, Changsheng Xu.* <br>
CVPR 2023. [[PDF](https://arxiv.org/abs/2211.13203)] 
[[Github](https://github.com/zyxElsa/InST)] <br>

**Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation** <br>
*Narek Tumanyan, Michal Geyer, Shai Bagon, Tali Dekel.* <br>
CVPR 2023. [[PDF](https://arxiv.org/abs/2211.12572)] 
[[Github](https://github.com/MichalGeyer/plug-and-play)] <br>

**Person Image Synthesis via Denoising Diffusion Model** <br>
*Ankan Kumar Bhunia, Salman Khan, Hisham Cholakkal, Rao Muhammad Anwer, Jorma Laaksonen, Mubarak Shah, Fahad Shahbaz Khan.* <br>
CVPR 2023. [[PDF](https://arxiv.org/abs/2211.12500)] 
[[Github](https://github.com/ankanbhunia/PIDM)] <br>

**Diffusion-based Image Translation using Disentangled Style and Content Representation** <br>
*Gihyun Kwon, Jong Chul Ye.* <br>
ICLR 2023. [[PDF](https://arxiv.org/abs/2209.15264)] 
[[Project](https://pnp-diffusion.github.io)] 
[[Github](https://github.com/anon294384/DiffuseIT)] <br>

**Dual Diffusion Implicit Bridges for Image-to-Image Translation** <br>
*Xuan Su, Jiaming Song, Chenlin Meng, Stefano Ermon.* <br>
ICLR 2023. [[PDF](https://arxiv.org/abs/2203.08382)] 
[[Github](https://github.com/suxuann/ddib)] <br>

**Restoring Vision in Adverse Weather Conditions with Patch-Based Denoising Diffusion Models** <br>
*Ozan Özdenizci, Robert Legenstein.* <br>
TPAMI 2023. [[PDF](https://arxiv.org/abs/2207.14626)] 
[[Github](https://github.com/IGITUGraz/WeatherDiffusion)] <br>


## 2022

**DiffFace: Diffusion-based Face Swapping with Facial Guidance** <br>
*Kihong Kim, Yunho Kim, Seokju Cho, Junyoung Seo, Jisu Nam, Kychul Lee, Seungryong Kim, KwangHee Lee.* <br>
arXiv 2022. [[PDF](https://arxiv.org/abs/2212.13344)] 
[[Project](https://hxngiee.github.io/DiffFace/)] 
[[Github](https://github.com/hxngiee/DiffFace)] <br>

**HS-Diffusion: Learning a Semantic-Guided Diffusion Model for Head Swapping** <br>
*Qinghe Wang, Lijie Liu, Miao Hua, Qian He, Pengfei Zhu, Bing Cao, Qinghua Hu.* <br>
arXiv 2022. [[PDF](https://arxiv.org/abs/2212.06458)] 
[[Github](https://github.com/qinghew/HS-Diffusion)] <br>

**Diffstyler: Controllable dual diffusion for text-driven image stylization** <br>
*Nisha Huang, Yuxin Zhang, Fan Tang, Chongyang Ma, Haibin Huang, Yong Zhang Weiming Dong, Changsheng Xu.* <br>
arXiv 2022. [[PDF](https://arxiv.org/abs/2211.10682)] 
[[Github](https://github.com/haha-lisa/Diffstyler.git)] <br>

**DiffGAR: Model-Agnostic Restoration from Generative Artifacts Using Image-to-Image Diffusion Models** <br>
*Yueqin Yin, Lianghua Huang, Yu Liu, Kaiqi Huang.* <br>
arXiv 2022. [[PDF](https://arxiv.org/abs/2210.08573)] <br>

**Unifying Diffusion Models' Latent Space, with Applications to CycleDiffusion and Guidance** <br>
*Chen Henry Wu, Fernando De la Torre.* <br>
arXiv 2022. [[PDF](https://arxiv.org/abs/2210.05559)] 
[[Github-1](https://github.com/ChenWu98/cycle-diffusion)] 
[[Github-2](https://github.com/ChenWu98/unified-generative-zoo)] <br>

**Anatomically constrained CT image translation for heterogeneous blood vessel segmentation** <br>
*Giammarco La Barbera, Haithem Boussaid, Francesco Maso, Sabine Sarnacki, Laurence Rouet, Pietro Gori, Isabelle Bloch.* <br>
BMVC 2022. [[PDF](https://arxiv.org/abs/2210.01713)] <br>

**Draw Your Art Dream: Diverse Digital Art Synthesis with Multimodal Guided Diffusion** <br>
*Nisha Huang, Fan Tang, Weiming Dong, Changsheng Xu.* <br>
arXiv 2022. [[PDF](https://arxiv.org/abs/2209.13360)]
[[Github](https://github.com/haha-lisa/mgad-multimodal-guided-artwork-diffusion)] <br>

**MIDMs: Matching Interleaved Diffusion Models for Exemplar-based Image Translation** <br>
*Junyoung Seo, Gyuseong Lee, Seokju Cho, Jiyoung Lee, Seungryong Kim.* <br>
arXiv 2022. [[PDF](https://arxiv.org/abs/2209.11047)]
[[Project](https://ku-cvlab.github.io/MIDMs/)] 
[[Github](https://github.com/KU-CVLAB/MIDMs/)] <br>

**Non-Uniform Diffusion Models** <br>
*Georgios Batzolis, Jan Stanczuk, Carola-Bibiane Schönlieb, Christian Etmann.* <br>
arXiv 2022. [[PDF](https://arxiv.org/abs/2207.09786)] <br>

**Unsupervised Medical Image Translation with Adversarial Diffusion Models** <br>
*Muzaffer Özbey, Salman UH Dar, Hasan A Bedel, Onat Dalmaz, Şaban Özturk, Alper Güngör, Tolga Çukur.* <br>
arXiv 2022. [[PDF](https://arxiv.org/abs/2207.08208)]
[[Github](https://github.com/icon-lab/syndiff)] <br>

**EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic Differential Equations** <br>
*Min Zhao, Fan Bao, Chongxuan Li, Jun Zhu.* <br>
NeurIPS 2022. [[PDF](https://arxiv.org/abs/2207.06635)] 
[[Github](https://github.com/ML-GSAI/EGSDE)] <br>

**Discrete Contrastive Diffusion for Cross-Modal and Conditional Generation** <br>
*Ye Zhu, Yu Wu, Kyle Olszewski, Jian Ren, Sergey Tulyakov, Yan Yan.* <br>
arXiv 2022. [[PDF](https://arxiv.org/abs/2206.07771)] 
[[Github](https://github.com/L-YeZhu/CDCD)] <br>

**Pretraining is All You Need for Image-to-Image Translation** <br>
*Tengfei Wang, Ting Zhang, Bo Zhang, Hao Ouyang, Dong Chen, Qifeng Chen, Fang Wen.* <br>
arXiv 2022. [[PDF](https://arxiv.org/abs/2205.12952)] 
[[Project](https://tengfei-wang.github.io/PITI/index.html)] 
[[Github](https://github.com/PITI-Synthesis/PITI)] <br>

**BBDM: Image-to-image Translation with Brownian Bridge Diffusion Models** <br>
*Bo Li, Kaitao Xue, Bin Liu, Yu-Kun Lai.* <br>
CVPR 2023. [[PDF](https://arxiv.org/abs/2205.07680)] 
[[Github](https://github.com/xuekt98/BBDM)] <br>

**The Swiss Army Knife for Image-to-Image Translation: Multi-Task Diffusion Models** <br>
*Julia Wolleb, Robin Sandkühler, Florentin Bieder, Philippe C. Cattin.* <br>
arXiv 2022. [[PDF](https://arxiv.org/abs/2204.02641)] <br>

**Denoising Diffusion Restoration Models** <br>
*Bahjat Kawar, Michael Elad, Stefano Ermon, Jiaming Song.* <br>
NeurIPS 2022. [[PDF](https://arxiv.org/abs/2201.11793)] 
[[Github](https://github.com/bahjat-kawar/ddrm)] <br>


## 2021

**DiffuseMorph: Unsupervised Deformable Image Registration Along Continuous Trajectory Using Diffusion Models** <br>
*Boah Kim, Inhwa Han, Jong Chul Ye.* <br>
**Medical Image Translation**, KAIST <br>
arXiv 2021. [[PDF](https://arxiv.org/abs/2112.05149)] 
[[Github](https://github.com/DiffuseMorph/DiffuseMorph)] <br>

**Diffusion Autoencoders: Toward a Meaningful and Decodable Representation** <br>
*Konpat Preechakul, Nattanat Chatthee, Suttisak Wizadwongsa, Supasorn Suwajanakorn* <br>
**Base I2I translation**, VISTEC <br>
arXiv 2021. [[PDF](https://arxiv.org/abs/2111.15640)] 
[[Project](https://diff-ae.github.io/)] 
[[Github](https://github.com/phizaz/diffae)] <br>

**Conditional Image Generation with Score-Based Diffusion Models** <br>
*Georgios Batzolis, Jan Stanczuk, Carola-Bibiane Schönlieb, Christian Etmann.* <br>
**Base I2I translation**, University of Cambridge <br>
arXiv 2021. [[PDF](https://arxiv.org/abs/2111.13606)] 
[[Github](https://github.com/GBATZOLIS/conditional_score_diffusion)] <br>

**Palette: Image-to-Image Diffusion Models** <br>
*Chitwan Saharia, William Chan, Huiwen Chang, Chris A. Lee, Jonathan Ho, Tim Salimans, David J. Fleet, Mohammad Norouzi.* <br>
**Base I2I translation**, Google Research <br>
SIGRAPH 2021. [[PDF](https://arxiv.org/abs/2111.05826)] 
[[Github](https://github.com/Janspiry/Palette-Image-to-Image-Diffusion-Models)] <br>

**DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation** <br>
*Gwanghyun Kim, Taesung Kwon, Jong Chul Ye.* <br>
**Else papers**, KAIST <br>
CVPR 2022. [[PDF](https://arxiv.org/abs/2110.02711)] 
[[Github](https://github.com/gwang-kim/DiffusionCLIP)] <br>

**ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models** <br>
*Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, Sungroh Yoon.* <br>
**Base I2I translation**, Seoul National University & Samsung <br>
ICCV 2021 (Oral). [[PDF](https://arxiv.org/abs/2108.02938)] 
[[Github](https://github.com/jychoi118/ilvr_adm)] <br>

**UNIT-DDPM: UNpaired Image Translation with Denoising Diffusion Probabilistic Models** <br>
*Hiroshi Sasaki, Chris G. Willcocks, Toby P. Breckon.* <br>
**Base I2I translation**, Durham University <br>
arXiv 2021. [[PDF](https://arxiv.org/abs/2104.05358)] 
[[Github](https://github.com/konkuad/UNIT-DDPM-Unofficial)] <br>
